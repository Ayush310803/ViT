{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHe+m3o1iJrwW1nJ1PleCn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayush310803/ViT/blob/main/Unettrainipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow-datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JfgHSTUl-wb",
        "outputId": "34114297-9e8f-4f4c-8bd3-563ea4f45720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.11/dist-packages (4.9.7)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (1.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (8.1.8)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (0.1.9)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (4.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (1.26.4)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (4.25.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (17.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (2.32.3)\n",
            "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (1.16.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (2.5.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (4.67.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (1.17.2)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (0.6.0)\n",
            "Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (1.11.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (2024.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (6.5.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (4.12.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2025.1.31)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow-datasets) (25.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from promise->tensorflow-datasets) (1.17.0)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from simple-parsing->tensorflow-datasets) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /usr/local/lib/python3.11/dist-packages (from tensorflow-metadata->tensorflow-datasets) (1.66.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DcO5m5Fjt8D"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "builder = tfds.builder('oxford_iiit_pet:4.*.*')\n",
        "\n",
        "builder.download_and_prepare()\n",
        "\n",
        "dataset = builder.as_data_source()\n",
        "info = builder.info\n",
        "print(info)"
      ],
      "metadata": {
        "id": "rHJ5UiEXjxer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbca0077-3711-4571-f65e-c33f730a14bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfds.core.DatasetInfo(\n",
            "    name='oxford_iiit_pet',\n",
            "    full_name='oxford_iiit_pet/4.0.0',\n",
            "    description=\"\"\"\n",
            "    The Oxford-IIIT pet dataset is a 37 category pet image dataset with roughly 200\n",
            "    images for each class. The images have large variations in scale, pose and\n",
            "    lighting. All images have an associated ground truth annotation of breed and\n",
            "    species. Additionally, head bounding boxes are provided for the training split,\n",
            "    allowing using this dataset for simple object detection tasks. In the test\n",
            "    split, the bounding boxes are empty.\n",
            "    \"\"\",\n",
            "    homepage='http://www.robots.ox.ac.uk/~vgg/data/pets/',\n",
            "    data_dir='/root/tensorflow_datasets/oxford_iiit_pet/4.0.0',\n",
            "    file_format=array_record,\n",
            "    download_size=Unknown size,\n",
            "    dataset_size=773.68 MiB,\n",
            "    features=FeaturesDict({\n",
            "        'file_name': Text(shape=(), dtype=string),\n",
            "        'head_bbox': BBoxFeature(shape=(4,), dtype=float32),\n",
            "        'image': Image(shape=(None, None, 3), dtype=uint8),\n",
            "        'label': ClassLabel(shape=(), dtype=int64, num_classes=37),\n",
            "        'segmentation_mask': Image(shape=(None, None, 1), dtype=uint8),\n",
            "        'species': ClassLabel(shape=(), dtype=int64, num_classes=2),\n",
            "    }),\n",
            "    supervised_keys=('image', 'label'),\n",
            "    disable_shuffling=False,\n",
            "    splits={\n",
            "        'test': <SplitInfo num_examples=3669, num_shards=4>,\n",
            "        'train': <SplitInfo num_examples=3680, num_shards=4>,\n",
            "    },\n",
            "    citation=\"\"\"@InProceedings{parkhi12a,\n",
            "      author       = \"Parkhi, O. M. and Vedaldi, A. and Zisserman, A. and Jawahar, C.~V.\",\n",
            "      title        = \"Cats and Dogs\",\n",
            "      booktitle    = \"IEEE Conference on Computer Vision and Pattern Recognition\",\n",
            "      year         = \"2012\",\n",
            "    }\"\"\",\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "def data_source_to_tf_dataset(data_source, split, img_size=128):\n",
        "    def generator():\n",
        "        for example in data_source[split]:\n",
        "            image = example[\"image\"]\n",
        "            mask = example[\"segmentation_mask\"]\n",
        "\n",
        "            image = tf.image.resize(image, (img_size, img_size), method=\"nearest\")\n",
        "            mask = tf.image.resize(mask, (img_size, img_size), method=\"nearest\")\n",
        "\n",
        "            image = tf.cast(image, tf.float32) / 255.0\n",
        "            mask = tf.cast(mask, tf.int32)\n",
        "            mask = tf.squeeze(mask, axis=-1)\n",
        "\n",
        "            yield image, mask\n",
        "\n",
        "    output_signature = (\n",
        "        tf.TensorSpec(shape=(img_size, img_size, 3), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(img_size, img_size), dtype=tf.int32),\n",
        "    )\n",
        "\n",
        "    return tf.data.Dataset.from_generator(generator, output_signature=output_signature)\n",
        "\n",
        "IMG_SIZE = 128\n",
        "train_dataset = data_source_to_tf_dataset(dataset, split='train', img_size=IMG_SIZE)\n",
        "test_dataset = data_source_to_tf_dataset(dataset, split='test', img_size=IMG_SIZE)"
      ],
      "metadata": {
        "id": "do9BZEhmq6w9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "train_batches = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "test_batches = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "validation_batches = test_dataset.take(128).batch(BATCH_SIZE)\n",
        "test_batches = test_dataset.skip(128).take(669).batch(BATCH_SIZE)\n"
      ],
      "metadata": {
        "id": "1k5xf_d6o_le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def double_conv_block(x, n_filters):\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "\n",
        "   return x"
      ],
      "metadata": {
        "id": "HQ8eJvKHpYxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def downsample_block(x, n_filters):\n",
        "   f = double_conv_block(x, n_filters)\n",
        "   p = layers.MaxPool2D(2)(f)\n",
        "   p = layers.Dropout(0.3)(p)\n",
        "\n",
        "   return f, p"
      ],
      "metadata": {
        "id": "beuO7pwVpY8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upsample_block(x, conv_features, n_filters):\n",
        "   x = layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
        "   x = layers.concatenate([x, conv_features])\n",
        "   x = layers.Dropout(0.3)(x)\n",
        "   x = double_conv_block(x, n_filters)\n",
        "\n",
        "   return x"
      ],
      "metadata": {
        "id": "dff2-lWcpZJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_unet_model(input_shape=(128, 128, 3)):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    f1, p1 = downsample_block(inputs, 64)\n",
        "    f2, p2 = downsample_block(p1, 128)\n",
        "    f3, p3 = downsample_block(p2, 256)\n",
        "    f4, p4 = downsample_block(p3, 512)\n",
        "\n",
        "    bottleneck = double_conv_block(p4, 1024)\n",
        "\n",
        "    u6 = upsample_block(bottleneck, f4, 512)\n",
        "    u7 = upsample_block(u6, f3, 256)\n",
        "    u8 = upsample_block(u7, f2, 128)\n",
        "    u9 = upsample_block(u8, f1, 64)\n",
        "\n",
        "    outputs = layers.Conv2D(4, 1, padding=\"same\", activation=\"softmax\")(u9)\n",
        "\n",
        "    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
        "    return unet_model"
      ],
      "metadata": {
        "id": "CzJAdaE0pZT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet_model = build_unet_model()"
      ],
      "metadata": {
        "id": "BcMyK6TupoDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "C0qepsaBpsDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 5\n",
        "\n",
        "\n",
        "TRAIN_LENGTH = info.splits[\"train\"].num_examples\n",
        "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
        "\n",
        "VAL_SUBSPLITS = 5\n",
        "TEST_LENGTH = info.splits[\"test\"].num_examples\n",
        "VALIDATION_STEPS = TEST_LENGTH // BATCH_SIZE // VAL_SUBSPLITS\n",
        "\n",
        "model_history = unet_model.fit(\n",
        "    train_batches,\n",
        "    epochs=NUM_EPOCHS,\n",
        "    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "    validation_steps=VALIDATION_STEPS,\n",
        "    validation_data=test_batches\n",
        ")"
      ],
      "metadata": {
        "id": "ZW7AO9f8p3v-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f1f18af-3d90-4500-ef0b-f9ea5630e883"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7938s\u001b[0m 139s/step - accuracy: 0.5454 - loss: 1.0147 - val_accuracy: 0.6486 - val_loss: 0.7868\n",
            "Epoch 2/5\n",
            "\u001b[1m 1/57\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:00:56\u001b[0m 65s/step - accuracy: 0.6045 - loss: 0.8307"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mask(pred_mask):\n",
        " pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        " pred_mask = pred_mask[..., tf.newaxis]\n",
        " return pred_mask[0]\n",
        "\n",
        "def show_predictions(dataset=None, num=1):\n",
        " if dataset:\n",
        "   for image, mask in dataset.take(num):\n",
        "     pred_mask = unet_model.predict(image)\n",
        "     display([image[0], mask[0], create_mask(pred_mask)])\n",
        " else:\n",
        "   display([sample_image, sample_mask,\n",
        "            create_mask(model.predict(sample_image[tf.newaxis, ...]))])\n",
        "\n",
        "count = 0\n",
        "for i in test_batches:\n",
        "   count +=1\n",
        "print(\"number of batches:\", count)"
      ],
      "metadata": {
        "id": "WvsKIulDp4lA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}